{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "\n",
        "#initializing cnn\n",
        "classifier = Sequential()\n",
        "\n",
        "#step 1 - convolution and polling\n",
        "classifier.add(Convolution2D(32,(3,3),input_shape=(64,64,1),activation='relu',padding='same'))\n",
        "classifier.add(Convolution2D(32,(3,3),input_shape=(64,64,1),activation='relu',padding='same'))\n",
        "classifier.add(MaxPooling2D(pool_size=(3,3),strides=2))\n",
        "\n",
        "#adding Dropout\n",
        "classifier.add(Dropout(0.5))\n",
        "\n",
        "#ADDING 2ND CONVOLUTION and polling\n",
        "classifier.add(Convolution2D(64,(3,3),input_shape=(64,64,1),activation='relu',padding='same'))\n",
        "classifier.add(Convolution2D(64,(3,3),input_shape=(64,64,1),activation='relu',padding='same'))\n",
        "classifier.add(MaxPooling2D(pool_size=(3,3),strides=2))\n",
        "\n",
        "#step3 Flatten\n",
        "classifier.add(Flatten())\n",
        "\n",
        "#creating ANN\n",
        "classifier.add(Dense(units=64,activation='relu'))\n",
        "classifier.add(Dense(units=8,activation='softmax'))\n",
        "\n",
        "#complie the CNN\n",
        "classifier.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "#Fitting the CNN to the images1\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#radom scaling are applied to the images before training the model\n",
        "#image augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "samplewise_center=True,\n",
        "vertical_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "        'input location of training set',\n",
        "        target_size=(64,64),#it should same as the input shape in convolaion\n",
        "        batch_size=32,\n",
        "        color_mode='grayscale',\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "        'input location of test set',\n",
        "        target_size=(64,64),#it should same as the input shape in convolaion\n",
        "        batch_size=32,\n",
        "        color_mode='grayscale',\n",
        "        class_mode='categorical')\n",
        "\n",
        "classifier.fit_generator(training_set,\n",
        "        steps_per_epoch=7999,#no of images in training set\n",
        "        epochs=1,\n",
        "        validation_data=test_set,\n",
        "        validation_steps=4000)\n",
        "\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "#load image path,target size of the image\n",
        "test_img= image.load_img('location of test image',target_size=(64,64),color_mode='grayscale')\n",
        "test_img=image.img_to_array(test_img)\n",
        "test_img=np.expand_dims(test_img,axis=0)\n",
        "result= classifier.predict(test_img)\n",
        "result\n",
        "\n",
        "#saving the model using it along with opencv \n",
        "from keras.models import load_model\n",
        "classifier.save('hand_gestures_1.h5') #name of the model"
      ],
      "metadata": {
        "id": "Y3hbj6q6D3zb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}